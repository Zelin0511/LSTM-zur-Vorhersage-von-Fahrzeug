{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693ae316-44f7-4aae-92b4-dcc064a28554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "批量预测进度: 100%|██████████████████████████████████████████████████████████████████| 391/391 [00:19<00:00, 19.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm  # 导入 tqdm\n",
    "\n",
    "# 读取训练好的模型\n",
    "model = load_model('predict_model.h5')\n",
    "\n",
    "# 读取需要预测的数据\n",
    "Import_csv_file = './merged_output.csv'\n",
    "Import_df = pd.read_csv(Import_csv_file)\n",
    "\n",
    "# 删除重复的 'Time' 列，假设 'Time' 列在第一列和第七列都有\n",
    "Import_df.drop(columns=['Time'], inplace=True)  # 删除第二个 'Time' 列\n",
    "\n",
    "# 获取表头\n",
    "x_headers = Import_df.columns.tolist()\n",
    "\n",
    "# 选择输入列（从第二列到第六列，控制和动力相关特征）\n",
    "X = Import_df[['AntriebsmomentVA', 'AntriebsmomentHA', 'Lenkwinkel', 'BremsmomentVA', 'BremsmomentHA']].values\n",
    "\n",
    "# 归一化输入数据\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1))\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "# 获取输出数据\n",
    "Exoport_csv_file = './output.csv'  # 你可以根据需求选择正确的文件\n",
    "Exoport_merged_data = pd.read_csv(Exoport_csv_file)\n",
    "\n",
    "# 获取输出列头\n",
    "y_headers = Exoport_merged_data.columns.tolist()\n",
    "\n",
    "# 选择输出列（如车辆状态和行为相关特征）\n",
    "y = Exoport_merged_data[['KS_X', 'KS_Y', 'Gierwinkel', 'Geschw_X', 'Geschw_Y', 'Giergeschwindigkeit']].values\n",
    "\n",
    "# 归一化输出数据\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# 将数据转换为LSTM所需的时间步格式\n",
    "def create_dataset(X, y, time_step=5, forecast_horizon=1):\n",
    "    X_data = []\n",
    "    for i in range(len(X) - time_step - forecast_horizon + 1):\n",
    "        input_x = X[i:(i + time_step)]  # 过去time_step个时间步的数据\n",
    "        input_y = y[i + time_step:i + time_step + forecast_horizon]  # 对应的目标数据\n",
    "        \n",
    "        X_data.append(input_x)\n",
    "    return np.array(X_data)\n",
    "\n",
    "\n",
    "time_step = 5  # 输入时间步数\n",
    "forecast_horizon = 1  # 预测1个未来时间步\n",
    "X_data = create_dataset(X_scaled, y_scaled, time_step, forecast_horizon)\n",
    "\n",
    "# 批量预测，开启 Keras 的进度条\n",
    "X_data_reshaped = X_data.reshape(-1, time_step, X.shape[1])\n",
    "#y_pred = model.predict(X_data_reshaped, verbose=1)  # verbose=1 显示进度条\n",
    "# 将前五个时间步的预测值设置为实际值\n",
    "#y_pred_with_actual = np.vstack((y_scaled[:5], y_pred))\n",
    "\n",
    "# 初始化预测数组：前五步用真实值\n",
    "y_pred = np.zeros_like(y_scaled)\n",
    "y_pred[:5] = y_scaled[:5]\n",
    "# 批量预测：从第6步开始，整体预测\n",
    "batch_inputs = X_data_reshaped[5:]  # 批量输入数据\n",
    "# 使用批量预测并添加进度条\n",
    "batch_size = 64  # 批量大小，可根据显存/内存调整\n",
    "\n",
    "for i in tqdm(range(0, len(batch_inputs), batch_size), desc=\"批量预测进度\"):\n",
    "    batch_seq = batch_inputs[i:i + batch_size]\n",
    "    batch_pred = model.predict(batch_seq, verbose=0)\n",
    "    \n",
    "    # 存储预测结果\n",
    "    y_pred[5 + i:5 + i + len(batch_pred)] = batch_pred\n",
    "\n",
    "# 最终预测结果\n",
    "y_pred_with_actual = y_pred\n",
    "\n",
    "# 从第六步开始批量预测，添加 tqdm 进度条\n",
    "#for i in tqdm(range(5, len(X_data_reshaped)), desc=\"批量预测进度\"):\n",
    "    # 构造输入：取前 time_step 步的数据作为输入\n",
    "    #input_seq = X_data_reshaped[i - time_step + 1:i + 1]\n",
    "    \n",
    "    # 预测当前时间步\n",
    "    #pred = model.predict(input_seq, verbose=0)\n",
    "    \n",
    "    # 存储预测结果\n",
    "    #y_pred[i] = pred[-1]\n",
    "\n",
    "# 反归一化预测结果\n",
    "y_pred_reshaped = np.array(y_pred).reshape(-1, 6)\n",
    "y_pred_rescaled = scaler_y.inverse_transform(y_pred_reshaped).reshape(len(y_pred), forecast_horizon, 6)\n",
    "\n",
    "\n",
    "# 将预测结果转换为DataFrame并与输入数据合并\n",
    "pred_df = pd.DataFrame(y_pred_rescaled.reshape(-1, 6))\n",
    "pred_df.columns = y_headers[1:]  # 输出的列名\n",
    "\n",
    "# 将预测结果与原始输入数据合并\n",
    "merged_data = pd.concat([Import_df, pred_df], axis=1)\n",
    "\n",
    "# 保存结果到CSV文件\n",
    "merged_data.to_csv('pred_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7654388c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f874cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
