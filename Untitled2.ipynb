{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1143786-d593-499a-8c04-b11fabbaaa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zelin\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 4ms/step - loss: 0.0049\n",
      "Epoch 2/10\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 8.6458e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 7.7922e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 7.2233e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 6.9039e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 6.6530e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 6.4147e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m7032/7032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 6.1018e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m2275/7032\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 6.0978e-04"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 训练部分\n",
    "train_folder = \"Training\"\n",
    "input_files = []\n",
    "output_files = []\n",
    "\n",
    "# 遍历 Training 目录，收集所有输入和输出文件\n",
    "for subdir in os.listdir(train_folder):\n",
    "    subdir_path = os.path.join(train_folder, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        input_file = os.path.join(subdir_path, \"Importdata_4ms.csv\")\n",
    "        output_file = os.path.join(subdir_path, \"Exportdata_4ms.csv\")\n",
    "        if os.path.exists(input_file) and os.path.exists(output_file):\n",
    "            input_files.append(input_file)\n",
    "            output_files.append(output_file)\n",
    "\n",
    "# 读取所有输入和输出数据\n",
    "df_inputs = []\n",
    "df_outputs = []\n",
    "for i in range(len(input_files)):\n",
    "    df_input = pd.read_csv(input_files[i])\n",
    "    df_output = pd.read_csv(output_files[i])\n",
    "    df_inputs.append(df_input)\n",
    "    df_outputs.append(df_output)\n",
    "\n",
    "df_input = pd.concat(df_inputs, ignore_index=True)\n",
    "df_output = pd.concat(df_outputs, ignore_index=True)\n",
    "\n",
    "# 选择输入特征和输出特征\n",
    "input_features = [\"Time\", \"AntriebsmomentVA\", \"AntriebsmomentHA\", \"Lenkwinkel\", \"BremsmomentVA\", \"BremsmomentHA\", \"Geschw_S\"]\n",
    "output_features = [\"Time\", \"KS_X\", \"KS_Y\", \"Gierwinkel\", \"Geschw_X\", \"Geschw_Y\", \"Giergeschwindigkeit\"]\n",
    "\n",
    "# 归一化数据\n",
    "scalers = {}\n",
    "for feature in input_features:\n",
    "    scaler = MinMaxScaler()\n",
    "    df_input[feature] = scaler.fit_transform(df_input[[feature]])\n",
    "    scalers[feature] = scaler\n",
    "\n",
    "for feature in output_features:\n",
    "    scaler = MinMaxScaler()\n",
    "    df_output[feature] = scaler.fit_transform(df_output[[feature]])\n",
    "    scalers[feature] = scaler\n",
    "\n",
    "# 创建时间序列数据集\n",
    "def create_sequences(X, y, time_steps=10):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        Xs.append(X[i:i + time_steps])\n",
    "        ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# 训练 LSTM 模型\n",
    "X1, y1 = create_sequences(df_input[input_features].values, df_output[\"Giergeschwindigkeit\"].values)\n",
    "\n",
    "model1 = Sequential([\n",
    "    LSTM(50, activation='relu', return_sequences=True, input_shape=(X1.shape[1], X1.shape[2])),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model1.compile(optimizer='adam', loss='mse')\n",
    "model1.fit(X1, y1, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# 保存模型\n",
    "model1.save(\"giergeschwindigkeit_model.h5\")\n",
    "\n",
    "print(\"训练完成，模型已保存！\")\n",
    "\n",
    "# 预测部分\n",
    "print(\"开始预测...\")\n",
    "test_input_file = \"Test/input.csv\"\n",
    "df_test_input = pd.read_csv(test_input_file)\n",
    "\n",
    "# 归一化测试输入\n",
    "df_test_input_scaled = df_test_input.copy()\n",
    "for feature in input_features:\n",
    "    df_test_input_scaled[feature] = scalers[feature].transform(df_test_input[[feature]])\n",
    "\n",
    "# 创建测试集时间序列\n",
    "X_test = []\n",
    "time_steps = 10\n",
    "for i in range(len(df_test_input_scaled) - time_steps):\n",
    "    X_test.append(df_test_input_scaled[input_features].values[i:i + time_steps])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# 加载模型进行预测\n",
    "model1 = tf.keras.models.load_model(\"giergeschwindigkeit_model.h5\")\n",
    "giergeschwindigkeit_pred = model1.predict(X_test)\n",
    "\n",
    "# 反归一化\n",
    "giergeschwindigkeit_pred = scalers[\"Giergeschwindigkeit\"].inverse_transform(giergeschwindigkeit_pred)\n",
    "\n",
    "# 生成预测输出文件\n",
    "output_df = pd.DataFrame({\n",
    "    \"Time\": df_test_input[\"Time\"].values[-len(giergeschwindigkeit_pred):],\n",
    "    \"Giergeschwindigkeit\": giergeschwindigkeit_pred[:, 0]\n",
    "})\n",
    "\n",
    "output_df.to_csv(\"Test/predictions.csv\", index=False)\n",
    "\n",
    "print(\"预测完成，结果已保存到 Test/predictions.csv！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f18575-1d40-4dc2-8a3e-780d97b508ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
